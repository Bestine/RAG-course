{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a8dda7-f000-4af4-a604-0bbf4a388ecf",
   "metadata": {},
   "source": [
    "Got from [here](https://medium.com/@akriti.upadhyay/implementing-rag-with-langchain-and-hugging-face-28e3ea66c5f7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f5efc-5939-44bb-94d8-b6febbab653b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa5cfb59-c84b-454b-ad43-a79a9c0b7cd4",
   "metadata": {},
   "source": [
    "![](../images/langchain+huggingface.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba371dd-5aa0-43c5-b7f2-d3d6434f184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425d279e-b77f-4e42-819a-522d133c4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80c29f1-96f8-4003-9828-97cbf76e5b6b",
   "metadata": {},
   "source": [
    "**Document Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d4c2b9-a22b-4179-a610-f51ea004a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17072f04-50f6-4c0a-9f77-c69ea37410d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'instruction': 'When did Virgin Australia start operating?', 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}, page_content='\"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia\\'s domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\"'),\n",
       " Document(metadata={'instruction': 'Which is a species of fish? Tope or Rope', 'response': 'Tope', 'category': 'classification'}, page_content='\"\"')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the dataset name and the column containing the content\n",
    "dataset_name = \"databricks/databricks-dolly-15k\"\n",
    "page_content_column = \"context\"  # or any other column you're interested in\n",
    "\n",
    "# Create a loader instance\n",
    "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column)\n",
    "\n",
    "# Load the data\n",
    "data = loader.load()\n",
    "\n",
    "# Display the first 15 entries\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf13238-254a-445f-b9e5-64ee3d07bb41",
   "metadata": {},
   "source": [
    "**Document Transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331824c-042f-4790-9f49-de56b853896e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48f1be48-113d-4074-a404-e6736d82e944",
   "metadata": {},
   "source": [
    "![](../images/document-tranformers.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02a9d75-542c-4853-a565-4b8774c9fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RecursiveCharacterTextSplitter class with specific parameters.\n",
    "# It splits text into chunks of 1000 characters each with a 150-character overlap.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# 'data' holds the text you want to split, split the text into documents using the text splitter.\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e755d0f-0a60-4b94-9843-3c2248b4e733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'instruction': 'When did Virgin Australia start operating?', 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}, page_content='\"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia\\'s domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\"')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6dd24-f919-4d35-8389-49776978b0a3",
   "metadata": {},
   "source": [
    "**Text Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb1cfc-3d46-4e1c-9f70-11e93d8cfa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fe6f107-3d82-430a-abfc-65aac866c8e1",
   "metadata": {},
   "source": [
    "![](../images/text-embedding.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1285d64-cba6-44a3-b77b-b3299deea838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc12f2d7-31e7-4eac-9888-b4858e76f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7a667c-25fb-46bc-af6c-b522a43fbd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53343/3917115723.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the pre-trained model you want to use\n",
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "model_kwargs = {'device':'cpu'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1f70ea-8fb2-4cfb-969b-bab08bb2693f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.038338541984558105, 0.12346471846103668, -0.02864297851920128]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb131a-d88a-4db3-91d0-681b10b4645a",
   "metadata": {},
   "source": [
    "**Vector Stores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f084e8-fdd1-4a1e-b889-ff78182f48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0b2bd-431d-4152-b041-c48a159d6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815de358-09ed-46d3-aed2-a2793689233a",
   "metadata": {},
   "source": [
    "![](../images/vector-stores.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9edf73-b57b-42ad-85c6-8da071fefa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is cheesemaking?\"\n",
    "searchDocs = db.similarity_search(question)\n",
    "print(searchDocs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9d7ee-bda0-47c1-a59a-ca37f97d7f6e",
   "metadata": {},
   "source": [
    "**Preparing the LLM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a96a13-27a9-4186-933d-ac76a54098b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd1f8683-1685-4eb5-8d31-6f32713ed886",
   "metadata": {},
   "source": [
    "![](../images/model-preparation.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c4085-db71-4878-857d-6b2356fa6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer object by loading the pretrained \"Intel/dynamic_tinybert\" tokenizer.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Intel/dynamic_tinybert\")\n",
    "\n",
    "# Create a question-answering model object by loading the pretrained \"Intel/dynamic_tinybert\" model.\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"Intel/dynamic_tinybert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f9fd1-2467-4cd9-bd95-5ab3b08abfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model name you want to use\n",
    "model_name = \"Intel/dynamic_tinybert\"\n",
    "\n",
    "# Load the tokenizer associated with the specified model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Define a question-answering pipeline using the model and tokenizer\n",
    "question_answerer = pipeline(\n",
    "    \"question-answering\", \n",
    "    model=model_name, \n",
    "    tokenizer=tokenizer,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Create an instance of the HuggingFacePipeline, which wraps the question-answering pipeline\n",
    "# with additional model-specific arguments (temperature and max_length)\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=question_answerer,\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c9078-6a51-4e6d-8da9-f33467097a9a",
   "metadata": {},
   "source": [
    "**Retrievers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dca212-a676-4e25-9992-41e60d939561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5d34b77-9de1-468b-89ae-199c81291eb8",
   "metadata": {},
   "source": [
    "![](../images/retrievers.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d94214-e0de-4bcf-baf5-b9fbf6748319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever object from the 'db' using the 'as_retriever' method.\n",
    "# This retriever is likely used for retrieving data or documents from the database.\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1ec7d-95e5-4047-9670-af724c397bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is Cheesemaking?\")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcedbcb-4f3c-4d6c-b4c2-77fde45b2f3e",
   "metadata": {},
   "source": [
    "**Retrieval QA Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ba649-ec00-4709-9d80-819519dc8687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edeb82b8-a9bf-45e9-8cd0-7510f7e6f28f",
   "metadata": {},
   "source": [
    "![](../images/retrieval-chain.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1b5f7-c1ca-447c-b020-199a956055cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever object from the 'db' with a search configuration where it retrieves up to 4 relevant splits/documents.\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Create a question-answering instance (qa) using the RetrievalQA class.\n",
    "# It's configured with a language model (llm), a chain type \"refine,\" the retriever we created, and an option to not return source documents.\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever, return_source_documents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a3ba3-96bf-441d-b9ed-c3c2d93eb516",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is Thomas Jefferson?\"\n",
    "result = qa.run({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
