{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7c981a-b54e-43f0-a58c-17a79de4d64d",
   "metadata": {},
   "source": [
    "learn from [here](https://huggingface.co/blog/ngxson/make-your-own-rag)\n",
    "\n",
    "Here is a simple RAG architecture \n",
    "![](../images/simple-RAG-architecture.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506acc20-2824-4d00-b744-3051ff1cdbe2",
   "metadata": {},
   "source": [
    "**Loading the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c6ff2e-bcdd-4019-8263-0a741e423c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 entries\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open('../data/cat-facts.txt', 'r') as file: \n",
    "    dataset = file.readlines()\n",
    "    print(f\"Loaded {len(dataset)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954de0e2-a685-4d7f-abbb-bf118e0bf907",
   "metadata": {},
   "source": [
    "**Implement the vector database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab64e7f-4784-416d-b97d-4ec9c34a46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4b6e4-5b79-45f4-b99d-635aeb0d0e6c",
   "metadata": {},
   "source": [
    "Now, let's implement the vector database.\n",
    "\n",
    "We will use the embedding model from ollama to convert each chunk into an embedding vector, then store the chunk and its corresponding vector in a list.\n",
    "\n",
    "Here is an example function to calculate the embedding vector for a given text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8609c9-0411-4eb4-9779-c75f95e5df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element in the VECTOR_DB will be a tuple (chunk, embedding)\n",
    "# The embedding is a list of floats, for example: [0.1, 0.04, -0.34, 0.21, ...]\n",
    "VECTOR_DB = []\n",
    "\n",
    "def add_chunk_to_database(chunk):\n",
    "    embedding = ollama.embed(\n",
    "        model = EMBEDDING_MODEL, \n",
    "        input = chunk\n",
    "    )['embeddings'][0]\n",
    "    VECTOR_DB.append((chunk, embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe9440-503b-4295-a740-d40a976e3a1b",
   "metadata": {},
   "source": [
    "Lets consider each line in the dataset as a chunk for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bfc2fa-b4f9-4d85-8667-35da785b5945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chunk 1/150 to the database\n",
      "Added chunk 2/150 to the database\n",
      "Added chunk 3/150 to the database\n",
      "Added chunk 4/150 to the database\n",
      "Added chunk 5/150 to the database\n",
      "Added chunk 6/150 to the database\n",
      "Added chunk 7/150 to the database\n",
      "Added chunk 8/150 to the database\n",
      "Added chunk 9/150 to the database\n",
      "Added chunk 10/150 to the database\n",
      "Added chunk 11/150 to the database\n",
      "Added chunk 12/150 to the database\n",
      "Added chunk 13/150 to the database\n",
      "Added chunk 14/150 to the database\n",
      "Added chunk 15/150 to the database\n",
      "Added chunk 16/150 to the database\n",
      "Added chunk 17/150 to the database\n",
      "Added chunk 18/150 to the database\n",
      "Added chunk 19/150 to the database\n",
      "Added chunk 20/150 to the database\n",
      "Added chunk 21/150 to the database\n",
      "Added chunk 22/150 to the database\n",
      "Added chunk 23/150 to the database\n",
      "Added chunk 24/150 to the database\n",
      "Added chunk 25/150 to the database\n",
      "Added chunk 26/150 to the database\n",
      "Added chunk 27/150 to the database\n",
      "Added chunk 28/150 to the database\n",
      "Added chunk 29/150 to the database\n",
      "Added chunk 30/150 to the database\n",
      "Added chunk 31/150 to the database\n",
      "Added chunk 32/150 to the database\n",
      "Added chunk 33/150 to the database\n",
      "Added chunk 34/150 to the database\n",
      "Added chunk 35/150 to the database\n",
      "Added chunk 36/150 to the database\n",
      "Added chunk 37/150 to the database\n",
      "Added chunk 38/150 to the database\n",
      "Added chunk 39/150 to the database\n",
      "Added chunk 40/150 to the database\n",
      "Added chunk 41/150 to the database\n",
      "Added chunk 42/150 to the database\n",
      "Added chunk 43/150 to the database\n",
      "Added chunk 44/150 to the database\n",
      "Added chunk 45/150 to the database\n",
      "Added chunk 46/150 to the database\n",
      "Added chunk 47/150 to the database\n",
      "Added chunk 48/150 to the database\n",
      "Added chunk 49/150 to the database\n",
      "Added chunk 50/150 to the database\n",
      "Added chunk 51/150 to the database\n",
      "Added chunk 52/150 to the database\n",
      "Added chunk 53/150 to the database\n",
      "Added chunk 54/150 to the database\n",
      "Added chunk 55/150 to the database\n",
      "Added chunk 56/150 to the database\n",
      "Added chunk 57/150 to the database\n",
      "Added chunk 58/150 to the database\n",
      "Added chunk 59/150 to the database\n",
      "Added chunk 60/150 to the database\n",
      "Added chunk 61/150 to the database\n",
      "Added chunk 62/150 to the database\n",
      "Added chunk 63/150 to the database\n",
      "Added chunk 64/150 to the database\n",
      "Added chunk 65/150 to the database\n",
      "Added chunk 66/150 to the database\n",
      "Added chunk 67/150 to the database\n",
      "Added chunk 68/150 to the database\n",
      "Added chunk 69/150 to the database\n",
      "Added chunk 70/150 to the database\n",
      "Added chunk 71/150 to the database\n",
      "Added chunk 72/150 to the database\n",
      "Added chunk 73/150 to the database\n",
      "Added chunk 74/150 to the database\n",
      "Added chunk 75/150 to the database\n",
      "Added chunk 76/150 to the database\n",
      "Added chunk 77/150 to the database\n",
      "Added chunk 78/150 to the database\n",
      "Added chunk 79/150 to the database\n",
      "Added chunk 80/150 to the database\n",
      "Added chunk 81/150 to the database\n",
      "Added chunk 82/150 to the database\n",
      "Added chunk 83/150 to the database\n",
      "Added chunk 84/150 to the database\n",
      "Added chunk 85/150 to the database\n",
      "Added chunk 86/150 to the database\n",
      "Added chunk 87/150 to the database\n",
      "Added chunk 88/150 to the database\n",
      "Added chunk 89/150 to the database\n",
      "Added chunk 90/150 to the database\n",
      "Added chunk 91/150 to the database\n",
      "Added chunk 92/150 to the database\n",
      "Added chunk 93/150 to the database\n",
      "Added chunk 94/150 to the database\n",
      "Added chunk 95/150 to the database\n",
      "Added chunk 96/150 to the database\n",
      "Added chunk 97/150 to the database\n",
      "Added chunk 98/150 to the database\n",
      "Added chunk 99/150 to the database\n",
      "Added chunk 100/150 to the database\n",
      "Added chunk 101/150 to the database\n",
      "Added chunk 102/150 to the database\n",
      "Added chunk 103/150 to the database\n",
      "Added chunk 104/150 to the database\n",
      "Added chunk 105/150 to the database\n",
      "Added chunk 106/150 to the database\n",
      "Added chunk 107/150 to the database\n",
      "Added chunk 108/150 to the database\n",
      "Added chunk 109/150 to the database\n",
      "Added chunk 110/150 to the database\n",
      "Added chunk 111/150 to the database\n",
      "Added chunk 112/150 to the database\n",
      "Added chunk 113/150 to the database\n",
      "Added chunk 114/150 to the database\n",
      "Added chunk 115/150 to the database\n",
      "Added chunk 116/150 to the database\n",
      "Added chunk 117/150 to the database\n",
      "Added chunk 118/150 to the database\n",
      "Added chunk 119/150 to the database\n",
      "Added chunk 120/150 to the database\n",
      "Added chunk 121/150 to the database\n",
      "Added chunk 122/150 to the database\n",
      "Added chunk 123/150 to the database\n",
      "Added chunk 124/150 to the database\n",
      "Added chunk 125/150 to the database\n",
      "Added chunk 126/150 to the database\n",
      "Added chunk 127/150 to the database\n",
      "Added chunk 128/150 to the database\n",
      "Added chunk 129/150 to the database\n",
      "Added chunk 130/150 to the database\n",
      "Added chunk 131/150 to the database\n",
      "Added chunk 132/150 to the database\n",
      "Added chunk 133/150 to the database\n",
      "Added chunk 134/150 to the database\n",
      "Added chunk 135/150 to the database\n",
      "Added chunk 136/150 to the database\n",
      "Added chunk 137/150 to the database\n",
      "Added chunk 138/150 to the database\n",
      "Added chunk 139/150 to the database\n",
      "Added chunk 140/150 to the database\n",
      "Added chunk 141/150 to the database\n",
      "Added chunk 142/150 to the database\n",
      "Added chunk 143/150 to the database\n",
      "Added chunk 144/150 to the database\n",
      "Added chunk 145/150 to the database\n",
      "Added chunk 146/150 to the database\n",
      "Added chunk 147/150 to the database\n",
      "Added chunk 148/150 to the database\n",
      "Added chunk 149/150 to the database\n",
      "Added chunk 150/150 to the database\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(dataset): \n",
    "    add_chunk_to_database(chunk)\n",
    "    print(f\"Added chunk {i + 1}/{len(dataset)} to the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84b067-9173-48c3-8cd9-dac1dd967163",
   "metadata": {},
   "source": [
    "**Implement the retrieval function**\n",
    "\n",
    "let's implement the retrieval function that takes a query and returns the top N most relevant chunks based on cosine similarity. We can imagine that the higher the cosine similarity between the two vectors, the \"closer\" they are in the vector space. This means they are more similar in terms of meaning.\n",
    "\n",
    "Here is an example function to calculate the cosine similarity between two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa641eb5-9204-471f-8601-b077ef61b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dot_product = sum([x * y for x, y in zip(a, b)])\n",
    "    norm_a = sum([x ** 2 for x in a]) ** 0.5\n",
    "    norm_b = sum([x ** 2 for x in b]) ** 0.5\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263836d0-2282-4fbd-b4f2-024bb642788d",
   "metadata": {},
   "source": [
    "Now lets implement the retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7474ccf2-8b24-4b80-9577-cc4e51a06a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "    query_embedding = ollama.embed(\n",
    "        model = EMBEDDING_MODEL,\n",
    "        input = query\n",
    "    )[\"embeddings\"][0]\n",
    "\n",
    "    # temporary list to store (chunk, similarity) pairs\n",
    "    similarities = []\n",
    "    \n",
    "    for chunk, embedding in VECTOR_DB: \n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append((chunk, similarity))\n",
    "\n",
    "    # sort by similarity in descending order, becaase higher similarity means more relevant chunks \n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # finally, return the top N most relevant chunks \n",
    "    return similarities[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41b2b7-0293-4945-9ac1-6cec1bbcb06c",
   "metadata": {},
   "source": [
    "**Generation Phase** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9eec4-fc2a-4f54-817e-dccd8cd99e85",
   "metadata": {},
   "source": [
    "Here, he chatbot will generate a response based on the retrieved knowledge from the step above. This is done by simply add the chunks into the prompt that will be taken as input for the chatbot.\n",
    "\n",
    "For instance, a prompt can be constructed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8711899a-807c-47ab-877a-a320f33c2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask me a question:  tell me about cat speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved knowledge:\n",
      " - (similarity: 0.78) A cat can travel at a top speed of approximately 31 mph (49 km) over a short distance.\n",
      "\n",
      " - (similarity: 0.66) Cats are extremely sensitive to vibrations. Cats are said to detect earthquake tremors 10 or 15 minutes before humans can.\n",
      "\n",
      " - (similarity: 0.66) Researchers are unsure exactly how a cat purrs. Most veterinarians believe that a cat purrs by vibrating vocal folds deep in the throat. To do this, a muscle in the larynx opens and closes the air passage about 25 times per second.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let just ask a question \n",
    "input_query = input(\"Ask me a question: \")\n",
    "retrieved_knowledge = retrieve(input_query)\n",
    "\n",
    "# Let the LLM Answer it \n",
    "print(\"Retrieved knowledge:\")\n",
    "for chunk, similarity in retrieved_knowledge: \n",
    "    print(f\" - (similarity: {similarity:.2f}) {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190ec7b-b6f0-4e4b-a645-dbaff7a7992f",
   "metadata": {},
   "source": [
    "Lets now use  the `ollama` to generate the response. In this example, we will use `instruction_prompt` as system message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba6090b-4446-466e-821f-8da2f45159ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets instruct the bot  \n",
    "instruction_prompt = f\"\"\" You are a helpful chatbot. \n",
    "Use only the following pieces of context to answer the question. Don't make any new information:\n",
    "{'\\n'.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a200fab-5526-4514-a599-4ba201baa178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "According to the context, a cat can travel at approximately 31 mph (49 km) over a short distance."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model = LANGUAGE_MODEL, \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': instruction_prompt},\n",
    "        {'role': 'user', 'content': input_query}\n",
    "    ], \n",
    "    stream = True\n",
    ")\n",
    "\n",
    "# print the response from the chatbot in real-time \n",
    "print('Chatbot response:')\n",
    "for chunk in stream: \n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
